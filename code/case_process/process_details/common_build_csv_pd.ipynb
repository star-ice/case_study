{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generate all_cases.csv</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cn2an\n",
    "import chinese2digits as c2d\n",
    "import operator\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly as py\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode(connected=True)\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import requests\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter\n",
    "# from ipynb.fs.full.case_to_graph_only_method import convert_csv_graph, provinces_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"/Users/starice/Desktop/total_extracted_result/\"\n",
    "pre_dir = ['type1', 'type2', 'type3', 'type4']\n",
    "dir_name = ['2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "dir_sname = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "# csv_graph, _new_csvpd = convert_csv_graph(pre_dir[:], dir_name[:], dir_sname[:])\n",
    "csv_graph = nx.read_gpickle(\"/Users/starice/Desktop/csv_graph.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     38
    ]
   },
   "outputs": [],
   "source": [
    "plaintiff_titles = [\n",
    "    '上诉人', \n",
    "    '上诉人(一审原告)', \n",
    "    '上诉人(一审第三人)', \n",
    "    '上诉人(原告)', \n",
    "    '上诉人(原审原告)', \n",
    "    '上诉人(原审原告、反诉被告)', \n",
    "    '上诉人(原审原告人)', \n",
    "    '上诉人(原审第三人)', \n",
    "    '公益诉讼起诉人', \n",
    "    '再审申请人', \n",
    "    '再审申请人(一审原告)',\n",
    "    '再审申请人(一审原告、二审上诉人)',\n",
    "    '再审申请人(一审原告、二审被上诉人)', \n",
    "    '再审申请人(原审原告)',\n",
    "    '再审申请人(原审原告、二审上诉人)', \n",
    "    '再审申请人:(一审第三人、二审上诉人)', \n",
    "    '原告',\n",
    "    '原告(反诉被告)', \n",
    "    #     '抗诉机关', \n",
    "    #     '支持起诉人', # 根据支持起诉原则，支持起诉人不能以原告的身份起诉\n",
    "    #  '支持起诉机关', \n",
    "    '申诉人(一审原告、二审上诉人)',\n",
    "    '申诉人(一审原告、二审上诉人、再审申请人)',\n",
    "    '申诉人(一审原告、二审上诉人、原再审申请人)',\n",
    "    '申诉人(一审原告、二审被上诉人)',\n",
    "    '申诉人(原审原告)',\n",
    "    '申请再审人(一审原告、二审上诉人)', \n",
    "    '被上诉人(一审原告)', \n",
    "    '被上诉人(原审原告)',\n",
    "    '被上诉人(原审原告、反诉被告)', \n",
    "    '被上诉人(原甲原告)',\n",
    "    '被上诉人一(原审原告)',\n",
    "    '被申请人(一审原告、二审上诉人)',\n",
    "    '被申请人(一审原告、二审被上诉人)', \n",
    "    '被申请人(原审原告)', \n",
    "    '被申请人(一审公益诉讼起诉人、二审上诉人)']\n",
    "\n",
    "defendant_titles = [\n",
    "    '(一审被告、二审被上诉人)', \n",
    "    '一审被告', \n",
    "    '一审被告(二审上诉人)', \n",
    "    '一审被告、二审被上诉人', \n",
    "    '一审被告二审上诉人)', \n",
    "    '上上诉人(原审被告)', \n",
    "    '上诉人(一审被告)', \n",
    "    '上诉人(原审第一被告)', \n",
    "    '上诉人(原审被告)',\n",
    "    '上诉人(原审被告、反诉原告)',\n",
    "    '上诉人(原审被告一)', \n",
    "    '上诉人(被告)', \n",
    "#     '公益诉讼出庭人', \n",
    "    '再审申请人(一审被告)',\n",
    "    '再审申请人(一审被告、二审上诉人)',\n",
    "    '再审申请人(一审被告、二审被上诉人)', \n",
    "    '再审申请人(再审被告)', \n",
    "    '再审申请人(原审被告)', \n",
    "    '原审当事人(原审被告)',\n",
    "    '原审第三被告',\n",
    "    '原审第二被告',\n",
    "    '原审被告',\n",
    "    '被上诉人一(原审被告一)',\n",
    "    '被上诉人二(原审被告二)',\n",
    "    '原审被告(反诉原告)', \n",
    "    '特别授权被告', \n",
    "    '申请再审人(原审被告)',\n",
    "    '第一被告', \n",
    "    '第三被告',\n",
    "    '第二被告',\n",
    "    '被上诉人',\n",
    "    '被上诉人(一审被告)', \n",
    "    '被上诉人(原审第三人)',\n",
    "    '被上诉人(原审被告)',\n",
    "    '被上诉人(原审被告、反诉原告)',\n",
    "    '被上诉人(原审被告人)', \n",
    "    '被告',\n",
    "    '被告(反诉原告)',\n",
    "    '被告一',\n",
    "    '被告二', \n",
    "    '被申诉人(一审被告,二审被上诉人)',\n",
    "    '被申诉人(一审被告、二审上诉人)',\n",
    "    '被申诉人(一审被告、二审被上诉人)',\n",
    "    '被申诉人(一审被告、二审被上诉人、再审被申请人)',\n",
    "    '被申诉人(一审被告、二审被上诉人、原再审被申请人)',\n",
    "    '被申诉人(原审被告)',\n",
    "    '被申请人', \n",
    "    '被申请人(一审被告)',\n",
    "    '被申请人(一审被告,二审被上诉人)',\n",
    "    '被申请人(一审被告、二审上诉人)',\n",
    "    '被申请人(一审被告、二审被上诉人)', \n",
    "    '被申请人(原审被告)', \n",
    "    '被申请人(原审被告、二审被上诉人)'\n",
    "]\n",
    "\n",
    "cases = [(n, d) for n, d in csv_graph.nodes(data=True) \\\n",
    "               if d['bipartite']==0]\n",
    "plaintiffs = [(e1, e2, d) for e1, e2, d in csv_graph.edges(nbunch=[n[0] for n in cases], data=True) \\\n",
    "                    if d['title'] in plaintiff_titles]\n",
    "defendants = [(e1, e2, d) for e1, e2, d in csv_graph.edges(nbunch=[n[0] for n in cases], data=True) \\\n",
    "                    if d['title'] in defendant_titles]\n",
    "lawyers = [(n, d) for n, d in csv_graph.nodes(data=True) \\\n",
    "               if (d['bipartite']==1 and d['occupation']==\"律师\")]\n",
    "new_lawyers = [(e1, e2, d) for e1, e2, d in csv_graph.edges(nbunch=[n[0] for n in lawyers], data=True)]\n",
    "\n",
    "# Modify lawyer name and split multiple names into multiple rows\n",
    "pd_lawyers = pd.DataFrame(({\"lawyer\": [i[0] for i in new_lawyers], \"case_id\": [i[1] for i in new_lawyers]}))\n",
    "pd_lawyers['lawyer_1'] = pd_lawyers['lawyer'].apply(lambda r: re.sub(r\"\\([^()]*\\)\", \"\", r))\n",
    "pd_lawyers['lawyer_2'] = pd_lawyers['lawyer_1'].apply(lambda r: r.split(\"、\"))\n",
    "pd_lawyers = pd_lawyers.explode('lawyer_2').reset_index(drop=True)[['case_id', 'lawyer_2']]\n",
    "pd_lawyers.rename(columns={\"lawyer_2\":\"lawyer\"}, inplace=True)\n",
    "# print(pd_lawyers.head())\n",
    "\n",
    "pd_plaintiffs = pd.DataFrame({\"case_id\": [i[0] for i in plaintiffs], \"plaintiff\": [i[1] for i in plaintiffs]})\n",
    "pd_defendants = pd.DataFrame(({\"case_id\": [i[0] for i in defendants], \"defendant\": [i[1] for i in defendants]}))\n",
    "pd_cases = pd.DataFrame({\"case_id\": [i[0] for i in cases], \\\n",
    "                        \"judgement_date\": [i[1]['judgement_date'] for i in cases], \\\n",
    "                         \"is_success\": [i[1]['is_success'] for i in cases], \\\n",
    "#                          \"lat\": [i[1]['lat'] for i in cases], \\\n",
    "#                          \"lon\": [i[1]['lon'] for i in cases], \\\n",
    "                         \"court_name\": [i[1]['court_name'] for i in cases], \\\n",
    "                         \"procedure\": [i[1]['procedure'] for i in cases], \\\n",
    "                         \"judge\": [i[1]['judge'] for i in cases], \\\n",
    "                         \"legalfee\": [i[1]['legalfee'] for i in cases], \\\n",
    "                         \"objectmoney\": [i[1]['objectmoney'] for i in cases], \\\n",
    "                         \"province\": [i[1]['province'] for i in cases], \\\n",
    "                         \"city\": [i[1]['city'] for i in cases], \\\n",
    "                         \"reason\": [i[1]['reason'] for i in cases], \\\n",
    "                         \"district\": [i[1]['district'] for i in cases], \\\n",
    "                         \"penalty\": [i[1]['penalty'] for i in cases]})\n",
    "pd_cases['year'] = pd.DatetimeIndex(pd_cases['judgement_date']).year\n",
    "pd_cases['month'] = pd.DatetimeIndex(pd_cases['judgement_date']).month\n",
    "pd_cases['day'] = pd.DatetimeIndex(pd_cases['judgement_date']).day\n",
    "all_cases = pd_cases.merge(pd_plaintiffs, on=\"case_id\", how=\"left\")\n",
    "all_cases = all_cases.merge(pd_defendants, on=\"case_id\", how=\"left\")\n",
    "all_cases = all_cases.merge(pd_lawyers, on=\"case_id\", how=\"left\")\n",
    "all_cases.drop(all_cases[all_cases['lawyer'].str.contains('X|x|\\*|之夫|之子', regex=True)==True].index, inplace=True)\n",
    "all_cases.drop(all_cases[all_cases['plaintiff'].str.contains('X|x|\\*|之夫|之子', regex=True)==True].index, inplace=True)\n",
    "# all_cases.drop(all_cases[all_cases['plaintiff'].isin([\"XX\", \"xx\", \"**\"])].index, inplace=True) #delete the cases with invalid plaintiff name\n",
    "all_cases.drop(all_cases[all_cases['defendant'].str.contains('X|x|\\*', regex=True)==True].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases['plaintiff'] = all_cases['plaintiff'].str.replace(r'=|;|,|。', '', regex=True)\n",
    "all_cases['defendant'] = all_cases['defendant'].str.replace(r'=|;|,|。', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases.to_csv('/Users/starice/OwnFiles/cityu/RA/case_study/data/total_extracted_result/all_cases.csv', encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
