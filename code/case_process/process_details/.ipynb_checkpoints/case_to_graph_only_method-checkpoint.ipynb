{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convert csv files to graphs</h2>\n",
    "<h2>Generate csv_graph.pickle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import networkx as nx\n",
    "import cn2an\n",
    "from networkx.algorithms import bipartite\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import operator\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly as py\n",
    "import plotly.offline as offline\n",
    "offline.init_notebook_mode(connected=True)\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import requests\n",
    "import chinese2digits as c2d\n",
    "import re\n",
    "from plotly.subplots import make_subplots\n",
    "# import pyecharts\n",
    "# import pyecharts.options as opts\n",
    "# from pyecharts.charts import BMap\n",
    "# from pyecharts.faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>工具类的定义</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     4,
     9,
     14,
     52
    ]
   },
   "outputs": [],
   "source": [
    "base_url = \"/Users/starice/Desktop/total_extracted_result/\"\n",
    "pre_dir = ['type1', 'type2', 'type3', 'type4']\n",
    "dir_name = ['2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "dir_sname = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "\n",
    "party_attributes = ['occupation', 'gender', 'birth_date', '住', '组织机构代码', '住址', '住所', \\\n",
    "                    '现住', '身份证住址', '代理权限', '户籍所在地', '身份号码', '地址', '身份证号码', \\\n",
    "                    '注册号', '户籍地', '经常居住地', '组织机构代码证', '代码', '户籍地址', '营业场所', \\\n",
    "                    '身份证地址', '所在地', '身份证登记住址', '经营业主', '机构代码', '执业证号', '户籍住所', \\\n",
    "                    '统一社会信用代码', '营业地', '经营地址', '籍贯', '工商注册号', '信用代码', '统一信用代码', '执照注册号']\n",
    "\n",
    "case_attributes = ['procedure', 'reason', 'court_name', 'judge', 'judgement_result', 'is_success', \\\n",
    "                        'judgement_date', 'cost_type1', 'cost_type2', 'cost_type3', 'cost_type4', 'penalty',\\\n",
    "                  'province', 'city', 'district', \\\n",
    "#                    'lat', 'lon', \\\n",
    "                   'legalfee', 'objectmoney', 'unknown_cost_type']\n",
    "\n",
    "plaintiff_titles = [\n",
    "    '上诉人', \n",
    "    '上诉人(一审原告)', \n",
    "    '上诉人(一审第三人)', \n",
    "    '上诉人(原告)', \n",
    "    '上诉人(原审原告)', \n",
    "    '上诉人(原审原告、反诉被告)', \n",
    "    '上诉人(原审原告人)', \n",
    "    '上诉人(原审第三人)', \n",
    "    '公益诉讼起诉人', \n",
    "    '再审申请人', \n",
    "    '再审申请人(一审原告)',\n",
    "    '再审申请人(一审原告、二审上诉人)',\n",
    "    '再审申请人(一审原告、二审被上诉人)', \n",
    "    '再审申请人(原审原告)',\n",
    "    '再审申请人(原审原告、二审上诉人)', \n",
    "    '再审申请人:(一审第三人、二审上诉人)', \n",
    "    '原告',\n",
    "    '原告(反诉被告)', \n",
    "    #     '抗诉机关', \n",
    "    #     '支持起诉人', # 根据支持起诉原则，支持起诉人不能以原告的身份起诉\n",
    "    #  '支持起诉机关', \n",
    "    '申诉人(一审原告、二审上诉人)',\n",
    "    '申诉人(一审原告、二审上诉人、再审申请人)',\n",
    "    '申诉人(一审原告、二审上诉人、原再审申请人)',\n",
    "    '申诉人(一审原告、二审被上诉人)',\n",
    "    '申诉人(原审原告)',\n",
    "    '申请再审人(一审原告、二审上诉人)', \n",
    "    '被上诉人(一审原告)', \n",
    "    '被上诉人(原审原告)',\n",
    "    '被上诉人(原审原告、反诉被告)', \n",
    "    '被上诉人(原甲原告)',\n",
    "    '被上诉人一(原审原告)',\n",
    "    '被申请人(一审原告、二审上诉人)',\n",
    "    '被申请人(一审原告、二审被上诉人)', \n",
    "    '被申请人(原审原告)', \n",
    "    '被申请人(一审公益诉讼起诉人、二审上诉人)']\n",
    "\n",
    "defendant_titles = [\n",
    "    '(一审被告、二审被上诉人)', \n",
    "    '一审被告', \n",
    "    '一审被告(二审上诉人)', \n",
    "    '一审被告、二审被上诉人', \n",
    "    '一审被告二审上诉人)', \n",
    "    '上上诉人(原审被告)', \n",
    "    '上诉人(一审被告)', \n",
    "    '上诉人(原审第一被告)', \n",
    "    '上诉人(原审被告)',\n",
    "    '上诉人(原审被告、反诉原告)',\n",
    "    '上诉人(原审被告一)', \n",
    "    '上诉人(被告)', \n",
    "#     '公益诉讼出庭人', \n",
    "    '再审申请人(一审被告)',\n",
    "    '再审申请人(一审被告、二审上诉人)',\n",
    "    '再审申请人(一审被告、二审被上诉人)', \n",
    "    '再审申请人(再审被告)', \n",
    "    '再审申请人(原审被告)', \n",
    "    '原审当事人(原审被告)',\n",
    "    '原审第三被告',\n",
    "    '原审第二被告',\n",
    "    '原审被告',\n",
    "    '被上诉人一(原审被告一)',\n",
    "    '被上诉人二(原审被告二)',\n",
    "    '原审被告(反诉原告)', \n",
    "    '特别授权被告', \n",
    "    '申请再审人(原审被告)',\n",
    "    '第一被告', \n",
    "    '第三被告',\n",
    "    '第二被告',\n",
    "    '被上诉人',\n",
    "    '被上诉人(一审被告)', \n",
    "    '被上诉人(原审第三人)',\n",
    "    '被上诉人(原审被告)',\n",
    "    '被上诉人(原审被告、反诉原告)',\n",
    "    '被上诉人(原审被告人)', \n",
    "    '被告',\n",
    "    '被告(反诉原告)',\n",
    "    '被告一',\n",
    "    '被告二', \n",
    "    '被申诉人(一审被告,二审被上诉人)',\n",
    "    '被申诉人(一审被告、二审上诉人)',\n",
    "    '被申诉人(一审被告、二审被上诉人)',\n",
    "    '被申诉人(一审被告、二审被上诉人、再审被申请人)',\n",
    "    '被申诉人(一审被告、二审被上诉人、原再审被申请人)',\n",
    "    '被申诉人(原审被告)',\n",
    "    '被申请人', \n",
    "    '被申请人(一审被告)',\n",
    "    '被申请人(一审被告,二审被上诉人)',\n",
    "    '被申请人(一审被告、二审上诉人)',\n",
    "    '被申请人(一审被告、二审被上诉人)', \n",
    "    '被申请人(原审被告)', \n",
    "    '被申请人(原审被告、二审被上诉人)'\n",
    "]\n",
    "\n",
    "\n",
    "def extract_penalty(row):\n",
    "    pmoney = [0]\n",
    "    if str(row['procedure'])==\"一审\":\n",
    "        penalty = eval(row['cost_type3'])\n",
    "        if len(penalty) > 0:\n",
    "            for i in penalty:\n",
    "                money_string = i[2].replace(\",\", \"\")\n",
    "                exresult = c2d.takeNumberFromString(money_string)\n",
    "                if len(exresult['digitsStringList']) > 0:\n",
    "                    money = exresult['digitsStringList'][0]\n",
    "                    pmoney.append(float(money))\n",
    "#             row['penalty'] = max(pmoney)\n",
    "#         else:\n",
    "#             penalty = eval(row['cost_type5']) #当赔偿金缺失时用共计金额替代，但是还需要优化金额类型的提取\n",
    "        row['penalty'] = max(pmoney)\n",
    "    return row\n",
    "def extract_objectmoney(row):\n",
    "    objectmoney = [0]\n",
    "    penalty = eval(row['cost_type2'])\n",
    "    if len(penalty) > 0:\n",
    "        for i in penalty:\n",
    "            money_string = i[2].replace(\",\", \"\")\n",
    "            exresult = c2d.takeNumberFromString(money_string)\n",
    "            if len(exresult['digitsStringList']) > 0:\n",
    "                money = exresult['digitsStringList'][0]\n",
    "                objectmoney.append(float(money))\n",
    "    row['objectmoney'] = max(objectmoney)\n",
    "    return row\n",
    "def extract_legalfee(row):\n",
    "    legalfee = []\n",
    "    if str(row['procedure'])==\"一审\":\n",
    "        penalty = eval(row['cost_type1'])\n",
    "        if len(penalty) > 0:\n",
    "            for i in penalty: \n",
    "                money_string = i[2].replace(\",\", \"\")\n",
    "                exresult = c2d.takeNumberFromString(money_string)\n",
    "                if len(exresult['digitsStringList']) > 0:\n",
    "                    money = exresult['digitsStringList'][0]\n",
    "                    legalfee.append(float(money))\n",
    "        row['legalfee'] = min(legalfee) if len(legalfee) > 0 else 0\n",
    "    return row\n",
    "\n",
    "def convert_csv_graph(pre_dir, dir_name, dir_sname, alternative_path = \"\"):\n",
    "    if alternative_path == \"\":\n",
    "        csv_path = base_url + \"total_extracted_json_result_\" + str(\"-\".join(pre_dir)) + \"_\" + \\\n",
    "        str(\"-\".join(dir_name)) + \"_\" + str(\"-\".join(dir_sname)) + \".csv\"\n",
    "    else:\n",
    "        print(\"alternative path is not none!\")\n",
    "        csv_path = alternative_path\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(\"csv文件不存在！\", csv_path)\n",
    "        return\n",
    "    csv_pd = pd.read_csv(csv_path, encoding=\"UTF-8\", converters={'party_info': eval})\n",
    "    \n",
    "    # 1. preparing the data\n",
    "    #  reformat the pandas data\n",
    "    csv_pd.judgement_date = pd.to_datetime(csv_pd['judgement_date'])\n",
    "    \n",
    "    #extrat the penalty, legalfee, and object money of each case\n",
    "    csv_pd = csv_pd.apply(lambda row: extract_penalty(row), axis=1)\n",
    "    csv_pd = csv_pd.apply(lambda row: extract_legalfee(row), axis=1)\n",
    "    csv_pd = csv_pd.apply(lambda row: extract_objectmoney(row), axis=1)\n",
    "    \n",
    "    #  expand all party info from the party info list to pandas rows(with index replicated)\n",
    "    new_csvpd = csv_pd.explode('party_info')\n",
    "    print(new_csvpd.head())\n",
    "    \n",
    "    _new_csvpd = pd.concat([new_csvpd, new_csvpd['party_info'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    #去掉有干扰性原告名称的案件\n",
    "    _new_csvpd = _new_csvpd.drop(_new_csvpd[_new_csvpd['name'].isin([\"xx\", \"XX\", \"**\", \"x\", \"X\", \"*\", \"xxx\", \"XXX\", \"***\"])].index)\n",
    "    _new_csvpd['relationship'] = _new_csvpd[['case_id', 'name']].apply(tuple, axis=1) #build the relationship for graph\n",
    "    \n",
    "    # 2. build bipartite graph\n",
    "    csv_graph = nx.DiGraph()\n",
    "    \n",
    "    #  Add nodes with the node attribute \"bipartite\"\n",
    "    csv_graph.add_nodes_from(list(_new_csvpd['case_id'].drop_duplicates()), bipartite=0)\n",
    "    csv_graph.add_nodes_from(list(_new_csvpd['name']), bipartite=1)\n",
    "    \n",
    "    #  Add edges only between nodes of opposite node sets\n",
    "    relationship = list(_new_csvpd['relationship'])\n",
    "    \n",
    "    # Add edge attributes\n",
    "    # dates = list(_new_type1['judgement_date'])\n",
    "    titles = list(_new_csvpd['title'])\n",
    "    provinces = list(_new_csvpd['province'])\n",
    "    cities = list(_new_csvpd['city'])\n",
    "    districts = list(_new_csvpd['district'])\n",
    "#     lats = list(_new_csvpd['lat'])\n",
    "#     lons = list(_new_csvpd['lon']) #为节省时间，暂时没有运行获取地理位置数据\n",
    "#     penalties = list(_new_csvpd['penalty'])\n",
    "    csv_graph.add_edges_from([(relationship[i][0], relationship[i][1], \\\n",
    "                                 {'province': provinces[i], 'city': cities[i], \\\n",
    "                                  'district': districts[i], 'title':titles[i], \\\n",
    "#                                   'lat': lats[i], 'lon': lons[i]\n",
    "                                 }\n",
    "                              )\n",
    "                                for i in range(len(relationship))])\n",
    "    \n",
    "    # Add node attributes\n",
    "    for index, row in _new_csvpd.iterrows():\n",
    "        for c in case_attributes:\n",
    "            csv_graph.nodes[row['case_id']][c] = row[c]\n",
    "        for p in party_attributes:\n",
    "            if p in list(_new_csvpd.columns):\n",
    "                csv_graph.nodes[row['name']][p] = row[p]\n",
    "    \n",
    "    return csv_graph, _new_csvpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lonlat_province(row_in_pd):\n",
    "    url = 'http://api.map.baidu.com/geocoding/v3/'\n",
    "    params = { 'address' : row_in_pd['province'],           \n",
    "               'ak' : 'gXNjFLdd8Ot1NzGGy5ZZDrkzuDIvZCt2',          # 百度密钥\n",
    "               'output': 'json'}          # 输出结果设置为json格式\n",
    "    res = requests.get(url,params)\n",
    "    if res.content:\n",
    "        result = json.loads(res.text)\n",
    "        if result['status']==0:\n",
    "            row_in_pd['province_lon'] = result['result']['location']['lng']\n",
    "            row_in_pd['province_lat'] = result['result']['location']['lat']\n",
    "    return row_in_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在后面绘制地区区域划分图会用到\n",
    "with open(\"/Users/starice/OwnFiles/cityu/RA/case_study/code/case_process/china_province.geojson\") as f:\n",
    "    provinces_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 构建案件--当事人关系图\n",
    "# alternative_path = '/Users/starice/OwnFiles/cityu/RA/case_study/data/total_extracted_result/modified.csv'\n",
    "# # alternative_path = ''\n",
    "# csv_graph, _new_csvpd = convert_csv_graph(pre_dir[:], dir_name[:], dir_sname[:], alternative_path)\n",
    "# nx.write_gpickle(csv_graph, \"/Users/starice/Desktop/csv_graph.gpickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
