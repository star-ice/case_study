{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import spacy\n",
    "# import zh_core_web_sm\n",
    "# import en_core_web_sm\n",
    "import zh_core_web_trf\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "from spacy.attrs import ORTH\n",
    "import re\n",
    "from spacy.tokens import Doc\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.symbols import POS\n",
    "from spacy.strings import StringStore\n",
    "from spacy.pipeline import Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"returnCode\":200,\"returnInfo\":\"请求成功\",\"returnData\":{\"id\":\"5ec8139c7116c36f1be3942a\",\"segments\":[{\"type\":null,\"typeText\":null,\"text\":\"广东省深圳市福田区人民法院\"},{\"type\":null,\"typeText\":null,\"text\":\"民 事 判 决 书\"},{\"type\":\"CASE_NO\",\"typeText\":\"案号\",\"text\":\"(2017)粤0304民初17204号\"},{\"type\":\"LITIGANT\",\"typeText\":\"当事人\",\"text\":\"原告许鹏飞,男,汉族,1982年8月8日出生。\"},{\"type\":\"LITIGANT\",\"typeText\":\"当事人\",\"text\":\"委托代理人张文利,女,汉族,1987年11月2日出生,住址陕西省蒲城县,系原告配偶。\"},{\"type\":\"LITIGANT\",\"typeText\":\"当事人\",\"text\":\"被告尹真贤,1987年9月27日出生。\"},{\"type\":\"TRIAL_PROCESS\",\"typeText\":\"审理经过\",\"text\":\"上列原告许鹏飞诉被告尹真贤产品责任纠纷一案,本院于2017年6月6日立案受理后,依法组成合议庭,于2017年10月20日公开开庭进行了审理,原告许鹏飞到庭参加诉讼,被告经本院依法传唤未到庭参加诉讼,本院依法进行缺席审理。本案现已审理终结。\"},{\"type\":\"PLAINTIFF_WORDS\",\"typeText\":\"原告诉称\",\"text\":\"原告诉称,原告在被告淘宝网店付款991.02元(人民币,下同),购买了5瓶“印度神药ELEPHANT”。原告收到后发现其为假药或不符合标准的产品。原告遂诉至法院,请求判令:1、被告退还购物款991.02元,并赔偿9991.02元;2、本案诉讼费用由被告承担。\"},{\"type\":\"DEFENDANT_WORDS\",\"typeText\":\"被告辩称\",\"text\":\"被告未出庭应诉,亦未提交书面答辩状。\"},{\"type\":\"ASCERTAIN\",\"typeText\":\"本院查明\",\"text\":\"经审理查明,原告于2017年5月23日通过淘宝网账户“张明zwlxpf”在被告淘宝网店“性用品批发商520”处购买了5瓶“2017印度巨象代购正品持久神油口男服用保健品勃起提高性功能”(即涉案产品),订单编号为22233728684034085,单价398元,经优惠省998.98元,涉案产品总价991.02元。涉案产品说明书注有如下内容:主要成分为壮阳果、鹿茸、野山参、淫羊藿、雄蚕蛾、红景天、鹿胎、海马等;批准文号:2016026;执行标准:Q/ZB2013-2016;生产批号:10032755;生产日期:201610;有效期至:202010。\"},{\"type\":\"ASCERTAIN\",\"typeText\":\"本院查明\",\"text\":\"另查,涉案产品说明书为网络截图,原告收到的涉案产品无附带说明书,也无生产日期、生产企业、合格证等任何标识,仅包装盒和药品瓶身印有“ELEPHANT”字样。\"},{\"type\":\"ASCERTAIN\",\"typeText\":\"本院查明\",\"text\":\"以上事实,有原告提交的相应产品实物照片、交易快照、商品信息等证据及开庭笔录为证,本院予以确认。\"},{\"type\":\"COURT_HELD\",\"typeText\":\"本院认为\",\"text\":\"本院认为,根据原告提供的证据材料及庭审查明的事实,被告向原告出售涉案产品实际上是销售行为,并非代购,原被告之间成立买卖合同关系。被告销售案产品无有效的批准文号和其他标识,亦无相应证据证明涉案产品具有合法来源,原告主张被告销售涉案产品的行为对其构成欺诈,具有事实与法律依据。原告要求被告退还货款991.02元,本院予以支持;原告要求被告赔偿9991.02元,超过法定标准,本院酌定被告按支付价款的十倍赔偿原告9910.2元。\"},{\"type\":\"COURT_HELD\",\"typeText\":\"本院认为\",\"text\":\"被告经本院合法传唤未到庭应诉,应承担相应的不利后果。\"},{\"type\":\"COURT_HELD\",\"typeText\":\"本院认为\",\"text\":\"综上,依照《中华人民共和国合同法》第一百三十条、《中华人民共和国食品安全法》第九十二条、第一百四十八条第二款《中华人民共和国民事诉讼法》第六十四条、第一百四十四条的规定,判决如下:\"},{\"type\":\"JUDGEMENT_RESULT\",\"typeText\":\"裁判结果\",\"text\":\"一、被告尹真贤应于本判决生效之日起十日内退还原告许鹏飞货款991.02元,并赔偿原告许鹏飞9910.2元;\"},{\"type\":\"JUDGEMENT_RESULT\",\"typeText\":\"裁判结果\",\"text\":\"二、驳回原告许鹏飞的其他诉讼请求。\"},{\"type\":\"JUDGEMENT_RESULT\",\"typeText\":\"裁判结果\",\"text\":\"如果未按本判决指定的期间履行给付金钱义务,应当依照《中华人民共和国民事诉讼法》第二百五十三条的规定,加倍支付迟延履行期间的债务利息。\"},{\"type\":\"JUDGEMENT_RESULT\",\"typeText\":\"裁判结果\",\"text\":\"本案案件受理费75元(已由原告预交),由被告负担。\"},{\"type\":\"JUDGEMENT_RESULT\",\"typeText\":\"裁判结果\",\"text\":\"如不服本判决,可在判决书送达之日起十五日内,向本院递交上诉状,并按对方当事人的人数提出副本,上诉于广东省深圳市中级人民法院,并应在收到预交上诉费通知次日起七日内预交上诉案件受理费。逾期不预交的,按自动撤回上诉处理。\"},{\"type\":\"JUDGEMENT_RESULT\",\"typeText\":\"裁判结果\",\"text\":\"(此页无正文)\"},{\"type\":\"JUDGE\",\"typeText\":\"审判人员\",\"text\":\"审 判 长 江红虹\"},{\"type\":\"JUDGE\",\"typeText\":\"审判人员\",\"text\":\"人民陪审员 周玉萍\"},{\"type\":\"JUDGE\",\"typeText\":\"审判人员\",\"text\":\"人民陪审员 侯 昆\"},{\"type\":\"JUDGE\",\"typeText\":\"审判人员\",\"text\":\"二〇一七年十一月二十日\"},{\"type\":\"JUDGE\",\"typeText\":\"审判人员\",\"text\":\"本件与原本核对无异\"},{\"type\":\"JUDGE\",\"typeText\":\"审判人员\",\"text\":\"书 记 员 徐 羚\"}],\"referencedType\":\"10\",\"caseTitle\":\"许鹏飞与尹真贤产品责任纠纷一审民事判决书\",\"caseNo\":\"（2017）粤0304民初17204号\",\"instrumentType\":\"判决书\",\"instrumentTypeId\":\"1\",\"procedure\":\"一审\",\"procedureId\":\"1\",\"reasons\":[{\"reasonId\":\"002\",\"reason\":\"民事案由\",\"isleaf\":false},{\"reasonId\":\"002009001009\",\"reason\":\"产品责任纠纷\",\"isleaf\":false}],\"reason\":\"产品责任纠纷\",\"court\":\"广东省深圳市福田区人民法院\",\"judicialGist\":\"\",\"lawClauseList\":[{\"law\":{\"id\":null,\"lawId\":null,\"title\":null,\"source\":null,\"lawName\":\"中华人民共和国合同法\",\"province\":null,\"lawNo\":null,\"pubDate\":null,\"effectiveDate\":null,\"state\":null,\"stateId\":null,\"href\":null,\"org\":null,\"orgIds\":null,\"orgIdsList\":null,\"effectLevel\":null,\"effectLevelId\":null,\"theme\":null,\"themeId\":null,\"rawData\":null,\"lawSegments\":null,\"hasClauses\":false,\"tiaoList\":null,\"md5String\":null,\"sortNo\":0.0,\"lawType\":null,\"partyLawType\":null,\"partyOrg\":null,\"partyEffectLevelCentral\":false,\"partyEffectLevelPlace\":null},\"lawId\":\"5b889d217f7e2a1cecba7aad\",\"tiao\":{\"law\":null,\"tiaoId\":null,\"tiao\":\"第一百三十条\",\"lawClauseList\":null},\"tiaoId\":\"130\",\"text\":\"《中华人民共和国合同法》第一百三十条\",\"kuanXiangId\":\"1\",\"kuan\":null,\"xiang\":null,\"content\":\"第一百三十条<br/>【定义】买卖合同是出卖人转移标的物的所有权于买受人，买受人支付价款的合同。\"},{\"law\":{\"id\":null,\"lawId\":null,\"title\":null,\"source\":null,\"lawName\":\"中华人民共和国食品安全法\",\"province\":null,\"lawNo\":null,\"pubDate\":null,\"effectiveDate\":null,\"state\":null,\"stateId\":null,\"href\":null,\"org\":null,\"orgIds\":null,\"orgIdsList\":null,\"effectLevel\":null,\"effectLevelId\":null,\"theme\":null,\"themeId\":null,\"rawData\":null,\"lawSegments\":null,\"hasClauses\":false,\"tiaoList\":null,\"md5String\":null,\"sortNo\":0.0,\"lawType\":null,\"partyLawType\":null,\"partyOrg\":null,\"partyEffectLevelCentral\":false,\"partyEffectLevelPlace\":null},\"lawId\":\"5baae97a9655942e0b4e08f8\",\"tiao\":{\"law\":null,\"tiaoId\":null,\"tiao\":\"第九十二条\",\"lawClauseList\":null},\"tiaoId\":\"92\",\"text\":\"《中华人民共和国食品安全法》第九十二条\",\"kuanXiangId\":null,\"kuan\":null,\"xiang\":null,\"content\":\"第九十二条<br/>进口的食品、食品添加剂、食品相关产品应当符合我国食品安全国家标准。<br/>进口的食品、食品添加剂应当经出入境检验检疫机构依照进出口商品检验相关法律、行政法规的规定检验合格。<br/>进口的食品、食品添加剂应当按照国家出入境检验检疫部门的要求随附合格证明材料。<br/>\"},{\"law\":{\"id\":null,\"lawId\":null,\"title\":null,\"source\":null,\"lawName\":\"中华人民共和国食品安全法\",\"province\":null,\"lawNo\":null,\"pubDate\":null,\"effectiveDate\":null,\"state\":null,\"stateId\":null,\"href\":null,\"org\":null,\"orgIds\":null,\"orgIdsList\":null,\"effectLevel\":null,\"effectLevelId\":null,\"theme\":null,\"themeId\":null,\"rawData\":null,\"lawSegments\":null,\"hasClauses\":false,\"tiaoList\":null,\"md5String\":null,\"sortNo\":0.0,\"lawType\":null,\"partyLawType\":null,\"partyOrg\":null,\"partyEffectLevelCentral\":false,\"partyEffectLevelPlace\":null},\"lawId\":\"5baae97a9655942e0b4e08f8\",\"tiao\":{\"law\":null,\"tiaoId\":null,\"tiao\":\"第一百四十八条\",\"lawClauseList\":null},\"tiaoId\":\"148\",\"text\":\"《中华人民共和国食品安全法》第一百四十八条第二款\",\"kuanXiangId\":\"2\",\"kuan\":\"第二款\",\"xiang\":null,\"content\":\"第一百四十八条<br/>消费者因不符合食品安全标准的食品受到损害的，可以向经营者要求赔偿损失，也可以向生产者要求赔偿损失。接到消费者赔偿要求的生产经营者，应当实行首负责任制，先行赔付，不得推诿；属于生产者责任的，经营者赔偿后有权向生产者追偿；属于经营者责任的，生产者赔偿后有权向经营者追偿。<br/><em>生产不符合食品安全标准的食品或者经营明知是不符合食品安全标准的食品，消费者除要求赔偿损失外，还可以向生产者或者经营者要求支付价款十倍或者损失三倍的赔偿金；增加赔偿的金额不足一千元的，为一千元。但是，食品的标签、说明书存在不影响食品安全且不会对消费者造成误导的瑕疵的除外。</em><br/>\"},{\"law\":{\"id\":null,\"lawId\":null,\"title\":null,\"source\":null,\"lawName\":\"中华人民共和国民事诉讼法\",\"province\":null,\"lawNo\":null,\"pubDate\":null,\"effectiveDate\":null,\"state\":null,\"stateId\":null,\"href\":null,\"org\":null,\"orgIds\":null,\"orgIdsList\":null,\"effectLevel\":null,\"effectLevelId\":null,\"theme\":null,\"themeId\":null,\"rawData\":null,\"lawSegments\":null,\"hasClauses\":false,\"tiaoList\":null,\"md5String\":null,\"sortNo\":0.0,\"lawType\":null,\"partyLawType\":null,\"partyOrg\":null,\"partyEffectLevelCentral\":false,\"partyEffectLevelPlace\":null},\"lawId\":\"5b889af17f7e2a1cecba78c8\",\"tiao\":{\"law\":null,\"tiaoId\":null,\"tiao\":\"第六十四条\",\"lawClauseList\":null},\"tiaoId\":\"64\",\"text\":\"《中华人民共和国民事诉讼法》第六十四条\",\"kuanXiangId\":null,\"kuan\":null,\"xiang\":null,\"content\":\"第六十四条<br/>【证明责任和职权探知】当事人对自己提出的主张，有责任提供证据。<br/>当事人及其诉讼代理人因客观原因不能自行收集的证据，或者人民法院认为审理案件需要的证据，人民法院应当调查收集。<br/>人民法院应当按照法定程序，全面地、客观地审查核实证据。<br/>\"},{\"law\":{\"id\":null,\"lawId\":null,\"title\":null,\"source\":null,\"lawName\":\"中华人民共和国民事诉讼法\",\"province\":null,\"lawNo\":null,\"pubDate\":null,\"effectiveDate\":null,\"state\":null,\"stateId\":null,\"href\":null,\"org\":null,\"orgIds\":null,\"orgIdsList\":null,\"effectLevel\":null,\"effectLevelId\":null,\"theme\":null,\"themeId\":null,\"rawData\":null,\"lawSegments\":null,\"hasClauses\":false,\"tiaoList\":null,\"md5String\":null,\"sortNo\":0.0,\"lawType\":null,\"partyLawType\":null,\"partyOrg\":null,\"partyEffectLevelCentral\":false,\"partyEffectLevelPlace\":null},\"lawId\":\"5b889af17f7e2a1cecba78c8\",\"tiao\":{\"law\":null,\"tiaoId\":null,\"tiao\":\"第一百四十四条\",\"lawClauseList\":null},\"tiaoId\":\"144\",\"text\":\"《中华人民共和国民事诉讼法》第一百四十四条\",\"kuanXiangId\":\"1\",\"kuan\":null,\"xiang\":null,\"content\":\"第一百四十四条<br/>【缺席审判】被告经传票传唤，无正当理由拒不到庭的，或者未经法庭许可中途退庭的，可以缺席判决。\"}],\"caseType\":\"2\",\"timeLineList\":[{\"year\":\"2017年\",\"monthDate\":\"5月23日\",\"date\":\"2017年5月23日\",\"dateForSort\":\"2017-05-22T16:00:00.000+0000\",\"text\":\"经审理查明,原告于2017年5月23日通过淘宝网账户“张明zwlxpf”在被告淘宝网店“性用品批发商520”处购买了5瓶“2017印度巨象代购正品持久神油口男服用保健品勃起提高性功能”(即涉案产品),订单编号为22233728684034085,单价398元,经优惠省998.98元,涉案产品总价991.02元\",\"segmentType\":\"本院查明\"},{\"year\":\"2017年\",\"monthDate\":\"6月6日\",\"date\":\"2017年6月6日\",\"dateForSort\":\"2017-06-05T16:00:00.000+0000\",\"text\":\"上列原告许鹏飞诉被告尹真贤产品责任纠纷一案,本院于2017年6月6日立案受理后,依法组成合议庭,于2017年10月20日公开开庭进行了审理,原告许鹏飞到庭参加诉讼,被告经本院依法传唤未到庭参加诉讼,本院依法进行缺席审理\",\"segmentType\":\"审理经过\"}],\"relatedInstrument\":[],\"hasExtractLaw\":true,\"courtHeld\":\"本院认为,根据原告提供的证据材料及庭审查明的事实,被告向原告出售涉案产品实际上是销售行为,并非代购,原被告之间成立买卖合同关系。被告销售案产品无有效的批准文号和其他标识,亦无相应证据证明涉案产品具有合法来源,原告主张被告销售涉案产品的行为对其构成欺诈,具有事实与法律依据。原告要求被告退还货款991.02元,本院予以支持;原告要求被告赔偿9991.02元,超过法定标准,本院酌定被告按支付价款的十倍赔偿原告9910.2元。\\n被告经本院合法传唤未到庭应诉,应承担相应的不利后果。\\n综上,依照《中华人民共和国合同法》第一百三十条、《中华人民共和国食品安全法》第九十二条、第一百四十八条第二款《中华人民共和国民事诉讼法》第六十四条、第一百四十四条的规定,判决如下:\\n\",\"collected\":0,\"lawyerMap\":{\"defenceType\":\"被告\",\"defenceList\":[{\"litigantName\":\"尹真贤\",\"org\":false,\"lawyer\":[]}],\"offenseType\":\"原告\",\"thirdType\":\"\",\"offenseList\":[{\"litigantName\":\"许鹏飞\",\"org\":false,\"lawyer\":[]}],\"thirdList\":[]},\"claim\":\"原告遂诉至法院,请求判令:1、被告退还购物款991.02元,并赔偿9991.02元;2、本案诉讼费用由被告承担。;\",\"mainJudgeShow\":null,\"source\":\"1\",\"judgementDate\":\"2017-11-20\",\"courtId\":\"4669\",\"wenshuId\":\"f6df07f7688b41f696d8a87300a818c9\"}}\n"
     ]
    }
   ],
   "source": [
    "total_basic_url = \"/Users/starice/Desktop/\"\n",
    "\n",
    "#处理网上爬下来的json\n",
    "with open('/Users/starice/OwnFiles/cityu/RA/type2/2017/11/json/5ec8139c7116c36f1be3942a.json', 'r', encoding=\"UTF-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(data)\n",
    "# print(type(data))\n",
    "dict_data = json.loads(data)\n",
    "# print(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# 定义一个合并字典值的工具类\n",
    "def merge_dict(x,y):\n",
    "    for k,v in x.items():\n",
    "                if k in y.keys():\n",
    "                    y[k] += v\n",
    "                else:\n",
    "                    y[k] = v\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case_truth_re_1': 1, 'case_truth_re_2': 4, 'case_truth_re_3': 4, 'case_truth_re_4': 0, 'case_truth_re_5': 0}\n"
     ]
    }
   ],
   "source": [
    "case_truth_relist = {'case_truth_re_1':1, 'case_truth_re_2':2, 'case_truth_re_3':3, 'case_truth_re_4':0, 'case_truth_re_5':0}\n",
    "court_opin_relist = {'case_truth_re_1':0, 'case_truth_re_2':2, 'case_truth_re_3':1}\n",
    "print(merge_dict(court_opin_relist, case_truth_relist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 使用指定的string list作为matcher词库去匹配\n",
    "party_titles = ['三被告共同委托代理人', '两被申诉人的共同委托代理人', '被上诉人(原审原告、反诉被告)', '上述两被告的共同委托诉讼代理人', '代表人', '公司代表人', '法定代表人', '特别授权被告', '上诉人(原审第三人)', '上述两被告委托代理人', '上述两被告共同委 托诉讼代理人', '再审申请人(原审被告)', '负责人', '委托代理人(特别授权)', '被申请人(一审被告、二审被上诉人)', '委托诉讼代理人(特别授权)', '被告委托代理人', '再审申请人', '诉讼委托代理人', '被告一', '拟稿人', '被上诉人(原审被告)', '上诉人(原审原告)', '被上诉人二(原审被告二)', '两被告共同委托代理人', '上诉人共同委托代理人', '原审被告', '被告二', '上诉人(原审被告、反诉原告)', '三上诉人的共同委托代理人', ' 再审申请人(一审原告)', '申诉人(一审原告、二审上诉人)', '支持起诉人', '两上诉人共同委托的诉讼代理人', '原审第二被告', '被上诉人一(原审被告一)', '一审被告', '原告', '被上诉人共同委托代理人', '原审第三人 ', '两原审被告共同委托代理人', '被告', '上述三上诉人共同委托代理人', '被上诉人(一审原告)', '授权代理人', '诉讼代表人', '被告(反诉原告)', '法人代表', '法人代表人', '法定代表人(负责人)', '两被上诉人共同的委托代理人', '上述两被告的委托 诉讼代理人', '申诉人(一审原告、二审被上诉人)', '(一审被告、二审被上诉人)', '一审第三人', '上诉人', '以上原告共同委托代理人', '以上二被上诉人的共同委托诉讼代理人', '申请再审人(原审被告)', '公益诉讼出庭人', '以上二被告共同委托代理人', '以上三被告共同委托代理人', '上述两被告的共同委托代理人', '以上两被告委托代理人', '被申诉人(一审被告、二审上诉人)', '两被上诉人的共同委托代理人', '二被告之共同委托诉讼代理人', '共同委托诉讼代理人', '两被告的共同委托代理人', '支持起诉机关', '上列两被上诉人委托代理人 ', '上述两被上诉人的共同委托诉讼代理人', '二被告共同委托诉讼代理人', '上列两被上诉人的委托代理人', ' 两被告共同的委托代理人', '上述两被告共同委托代理人', '被上诉人的共同委托诉讼代理人', '以上三被告共同的委托诉讼代理人', '抗诉机关', '被上诉人', '原审第三被告', '上诉人(一审原告)', '二被告共同委托代理人', '以上两被告共同委委托代理人', '两被申诉人共同委托诉讼代理人', '特别授权委托诉讼代理人', '两上诉 人共同委托代理人', '以上两被上诉人共同委托诉讼代理人', '上诉人(原审第一被告)', '申诉人(一审原告、二审上诉人、原再审申请人)', '第二被告', '被申请人(原审被告)', '上述两上诉人共同委托代理人', '被申诉人 (一审被告、二审被上诉人、原再审被申请人)', '再审申请人(一审原告、二审上诉人)', '两上诉人的共同委托代理人', '上列两被告的共同委托代理人', '上列两被告共同委托代理人', '被申请人(一审被告)', '原告共同委托诉讼代理人', '被申请人(一审被告、二审上诉人)', '上诉人共同委托诉讼代理人', '被申诉人(一审被告、二审 被上诉人)', '被上诉人(一审被告)', '上述二上诉人的共同委托诉讼代理人', '被申诉人(原审被告)', '二被上 诉人共同委托诉讼代理人', '上述两上诉人共同的委托诉讼代理人', '第三被告', '再审申请人(一审原告、二审被 上诉人)', '两上诉人共同委托诉讼代理人', '被申请人(一审原告、二审被上诉人)', '申诉人(原审原告)', '两被上诉人共同委托诉讼代理人', '诉讼代理人', '上诉人(一审被告)', '被申请人(原审原告)', '上诉人(原审被告)', '以上二上诉人共同的委托诉讼代理人', '上述两上诉人的共同委托代理人', '两上诉人的共同委托诉讼代理人', '上述两被上诉人委托诉讼代理人', '上上诉人(原审被告)', '第三人', '法定代理人', '被上诉人(原审第三人)', '原告(反诉被告)', '第一被告', '三被上诉人共同委托诉讼代理人', '委托代理人', '被申诉人(一审被告、二审被上诉人、再审被申请人)', '委托代理人(特别授权代理)', '两第三人的共同委托代理人', '被上诉人共同委托代理人(特别授权代理)', '再审申请人(一审被告、二审上诉人)', '以上两被告共同委托 代理人', '以上两被告的委托代理人', '上述两上诉人共同委托诉讼代理人', '上述被上诉人共同委托诉讼代理人 ', '二被委托代理人', '被申请人', '两被告共同委托诉讼代理人', '公益诉讼起诉人', '被上诉人(原审原告)', '上述两被上诉人共同委托代理人', '委托诉讼代理人', '上述被告共同委托诉讼代理人', '以上二被上诉 人委托代理人', '上列两被上诉人的共同委托代理人', '共同委托代理人', '再审申请人(原审原告)', '上述上诉人的委托诉讼代理人', '申诉人(一审原告、二审上诉人、再审申请人)', '二被上诉人的委托代理人', '上述两被上诉人的共同委托代理人', '上列二被告共同委托代理人', '以上两被告共同委托诉讼代理人', '执行事务合伙人', '投资人']\n",
    "\n",
    "party_infos = ['身份证地址', '联系地址', '通信地址', '现住', '住', '营业场所', '信用代码', '籍贯', '住址', '住址地', '所在地', '户籍所在地', '住所', '营业地', '身份证住址', '港澳证件号码', '原名称', '注册号', '组织机构代码', '非公司私营企业住所', '户籍地址', '身份证号码', '住', '组织机构代码证', '公⺠身份号码', '营业执照', '身份号码', '营业执照注册号', '住所地', '执照注册号', '经营场所', '身份证住址', ' 个体工商户营业执照注册', '机构代码', '户籍住所', '统一信用代码', '原名称', '身份证地址', '经营地址', '身份证登记住址', '组织机构代码证号', '执业证号', '曾用名', '统一社会信用代码', '工商注册号', '身份证号', '注册号', '营业场所', '居⺠身份证', '地址', '现住址', '身份证住址', '经常居住地', '代理权限', '户籍地', '营业执照号码', '公⺠身份证号', '中文名称 ', '住址', '所在地', '户籍地址', '组织机构代码证', '公⺠身份号码', '住所地', '代码', '经营业主', '经营场所', '身份证登记住址', '统一社会信用代码', '地址', '注册号', '营业场所', '居⺠身份证号码', '户籍地', '身份证住址']\n",
    "\n",
    "party_occupations = ['律师', '经理', '总经理', '董事长', '法务', '无职业', '业主', '员工', '店长', '主管', '经营者', '董事', '职员']\n",
    "\n",
    "cost_type = ['货款','价款','受理费','赔偿金','公证费','诉讼费','购物款','上诉费','公告费', '运费',\\\n",
    "             '交通费','误工费','打印费','鉴定费','邮寄费','赔偿款','医疗费','购酒款','购药款',\\\n",
    "             '住宿费','产品质量监督检验费','其他费用', '餐饮费', '购货款', '减半', '合计', '共计', '管辖权异议费']\n",
    "judge_titles = ['审判长', '审判员', '人民审判员', '助理审判员', '代理审判员', '人民陪审员']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新定义 token matcher 的 pattern 用作 party info 的 ner 匹配\n",
    "partytitle_token_pattern = [{\"TEXT\": {\"IN\": list(party_titles), \"NOT_IN\": [\"系原告\", \"与原告\"]}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = zh_core_web_trf.load()\n",
    "nlp = spacy.load(\"zh_core_web_trf\")\n",
    "patterns_ptitles = list(nlp.pipe(party_titles))\n",
    "patterns_pinfos = list(nlp.pipe(party_infos))\n",
    "patterns_poccups = list(nlp.pipe(party_occupations))\n",
    "# patterns_jtitles = list(nlp.pipe(judge_titles))\n",
    "patterns_jtitles = [nlp.make_doc(text) for text in judge_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output_dir=\"/Users/starice/Desktop/party_title_ner\"\n",
    "# print(\"Loading from\", output_dir)\n",
    "# nlp2 = spacy.load(output_dir)\n",
    "# patterns_ptitles2 = list(nlp2.pipe(party_titles))\n",
    "# patterns_pinfos2 = list(nlp2.pipe(party_infos))\n",
    "# patterns_poccups2 = list(nlp2.pipe(party_occupations))\n",
    "# patterns_jtitles2 = list(nlp2.pipe(judge_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Append words to user dict(like jieba.add_word) 帮助分词， 抛弃原先用jieba分词结果代替spacy分词的方法\n",
    "# nlp.tokenizer.pkuseg_update_user_dict(party) #这一步移到了处理单个case file方法内，避免大量的文件读取\n",
    "nlp.tokenizer.pkuseg_update_user_dict(cost_type)\n",
    "nlp.tokenizer.pkuseg_update_user_dict(party_titles)\n",
    "nlp.tokenizer.pkuseg_update_user_dict(party_infos)\n",
    "nlp.tokenizer.pkuseg_update_user_dict(judge_titles)\n",
    "#细微分词调节\n",
    "judgeresult_verbs = [\"赔偿\", \"退还\", \"负担\", \"返还\", \"支付\", \"赔付\", \"承担\", \"收取\", \"迳付\", \"给付\", \"交纳\", \"缴纳\"]\n",
    "nlp.tokenizer.pkuseg_update_user_dict(judgeresult_verbs)\n",
    "nlp.tokenizer.pkuseg_update_user_dict([\"本判决\", \"发生法律效力之日起\", \"发生法律效力后\", \\\n",
    "                                       \"本判决生效之日起\", \"本判决生效后\", \"于\", \"内\", \\\n",
    "                                       \"向\", \"计\"])\n",
    "nlp.tokenizer.pkuseg_update_user_dict([\"系原告\", \"与原告\", \"是原告\", \"和原告\", \"为原告\", \"系被告\", \"与被告\", \"是被告\", \"和被告\", \"为被告\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 使用entityruler帮助nlp识别特定的实体(费用类型、当事人等等)\n",
    "# Entity Ruler V3 (The use of add_pipe was changed because of the version update of spacy)\n",
    "# Add necessary patterns to global entityruler(including party_titles, party_infos, cost_types, judge_verbs from lists)\n",
    "# global_entityruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "global_entityruler = nlp.add_pipe(\"entity_ruler\", name=\"global_entityruler\", after=\"ner\")\n",
    "patterns_cost_type = [{\"label\": \"COST_TYPE\", \"pattern\": str(i)} for i in cost_type]\n",
    "patterns_party_title = [{\"label\": \"PARTY_TITLE\", \"pattern\": str(i)} for i in party_titles]\n",
    "patterns_party_info = [{\"label\": \"PARTY_INFO\", \"pattern\": str(i)} for i in party_infos]\n",
    "patterns_judgere_verbs = [{\"label\": \"JUDGE_VERB\", \"pattern\": str(i)} for i in judgeresult_verbs]\n",
    "global_entityruler.add_patterns(patterns_cost_type)\n",
    "global_entityruler.add_patterns(patterns_party_title)\n",
    "global_entityruler.add_patterns(patterns_party_info)\n",
    "global_entityruler.add_patterns(patterns_judgere_verbs)\n",
    "# nlp.add_pipe(\"global_entityruler\", after=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#使用自定义的pos mapping table来对一些词汇指定词性\n",
    "attribute_ruler = nlp.get_pipe(\"attribute_ruler\")\n",
    "tagger_pattern = [{\"TEXT\": {\"IN\": list(judgeresult_verbs)}}]\n",
    "tagger_attrs1 = {\"POS\": \"VERB\"}\n",
    "attribute_ruler.add(patterns=[tagger_pattern], attrs=tagger_attrs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "退还 VV VERB\n"
     ]
    }
   ],
   "source": [
    "doc_test = nlp(\"原告要求被告退还货款991.02元,本院予以支持**\")\n",
    "print(doc_test[3].text, doc_test[3].tag_, doc_test[3].pos_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MoneyRecognizer at 0x7fce9ddcfe20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用regex来帮助识别金额实体\n",
    "money_re = r\"(?P<money_amount>([零一二三四五六七八九十百千万亿角元\\d+\\.,]*)(?=[角|元])[角|元])\"\n",
    "\n",
    "# animal_hash = StringStore([u'MONEY_AMOUNT']) # <-- match id\n",
    "nlp.vocab.strings.add('MONEY_AMOUNT')\n",
    "\n",
    "@Language.factory(\"money_amount\", default_config={\"label\": \"MONEY_AMOUNT\", \"name\": \"money_amount\"})\n",
    "class MoneyRecognizer:\n",
    "    def __init__(self, nlp, name=\"money_amount\", label=\"MONEY_AMOUNT\"):\n",
    "        self.nlp = nlp\n",
    "        self.name = name\n",
    "        self.label = nlp.vocab.strings[label]  # get entity label ID\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        \"\"\"Apply the pipeline component on a Doc object and modify it if matches\n",
    "        are found. Return the Doc, so it can be processed by the next component\n",
    "        in the pipeline, if available.\n",
    "        \"\"\"\n",
    "        \n",
    "        expression = money_re\n",
    "#         spans = []  # keep the spans for later so we can merge them afterwards\n",
    "        for match in re.finditer(expression, doc.text):\n",
    "            start, end = match.span()\n",
    "            span = doc.char_span(start, end, label=self.label)\n",
    "            # This is a Span object or None if match doesn't map to valid token sequence\n",
    "            if span is not None:\n",
    "#                 spans.append(span)\n",
    "                doc.ents = list(doc.ents) + [span]\n",
    "#                 for s in spans:\n",
    "#                     s.merge\n",
    "        return doc\n",
    "                \n",
    "\n",
    "# money_component = MoneyRecognizer(nlp)  # initialise component\n",
    "# nlp.add_pipe(money_component, first=True)  # add before tagger in the pipeline\n",
    "nlp.add_pipe(\"money_amount\", before=\"tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer',\n",
       " 'money_amount',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'ner',\n",
       " 'global_entityruler',\n",
       " 'attribute_ruler']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将 entity识别结果应用到分词\n",
    "# nlp.add_pipe(\"merge_noun_chunks\")\n",
    "nlp.add_pipe(\"merge_entities\") #merge一般都在ner之后~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer', 'money_amount', 'tagger', 'parser', 'ner', 'global_entityruler', 'attribute_ruler', 'merge_entities']\n",
      "原告 PARTY_TITLE\n",
      "周冬梅 PERSON\n",
      "99.9元 MONEY_AMOUNT\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)\n",
    "doc = nlp(\"原告周冬梅,系原告,共99.9元\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.remove_pipe(\"merge_noun_chunks\")\n",
    "# nlp.remove_pipe(\"merge_entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def isInter(a,b):\n",
    "    result = list(set(a)&set(b))\n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def extract_loader(doc):\n",
    "    verb_1 = [\"承担\", \"负担\", \"交纳\", \"缴纳\"]\n",
    "    verb_2 = [\"赔偿\", \"退还\", \"返还\", \"支付\", \"赔付\", \"收取\", \"迳付\", \"给付\"]\n",
    "    loader = []\n",
    "    \n",
    "    # 如果是单纯的规定内容，例如”如不服本判决，则当事人需要交上诉费xx元...“，则判定为无效金额\n",
    "    invalid_cost = True\n",
    "    for token in doc:\n",
    "        if token.ent_type_ in [\"PARTY\", \"PARTY_TITLE\"]:\n",
    "            invalid_cost = False\n",
    "            break\n",
    "            \n",
    "    if isInter(verb_1, [str(i) for i in doc]):\n",
    "        for token in doc:\n",
    "            if token.dep_ == \"nsubj\" and token.ent_type_ == \"PARTY\":\n",
    "                return [(token.text)]\n",
    "            if (token.dep_ == \"nmod:prep\" and token.ent_type_ == \"PARTY\") or \\\n",
    "            (token.dep_ == \"conj\" and token.ent_type_ == \"PARTY\") or \\\n",
    "            (token.dep_ == \"compound:nn\" and token.ent_type_ == \"PARTY\"):\n",
    "                loader.append(token.text)\n",
    "            \n",
    "        if len(loader) == 0: #关键字匹配\n",
    "            party_changed = False\n",
    "            for token in doc:\n",
    "                if token.ent_type_ == \"PARTY_TITLE\":\n",
    "                    temp_loader = token.text\n",
    "                    party_changed = True\n",
    "                if token.ent_type_ == \"JUDGE_VERB\" and token.text in verb_1:\n",
    "                    if party_changed:\n",
    "                        loader.append(temp_loader)\n",
    "                        party_changed = False\n",
    "            loader = list(set(loader))\n",
    "    else:\n",
    "        temp_nsubj = []\n",
    "        #如果句子开头是个介词（例如限），则找ent type 是 party 或 party_title 的 dobj\n",
    "        if doc[0].dep_ == \"dep\":\n",
    "            for token in doc:\n",
    "                if token.dep_ == \"dobj\":\n",
    "                    if token.ent_type_ == \"PARTY\" or token.ent_type_ == \"PARTY_TITLE\" \\\n",
    "                    or token.ent_type_ in [\"PARTY\", \"PARTY_TITLE\", \"ORG\", \"PROPN\", \"PERSON\", \"GPE\"]:\n",
    "                        temp_nsubj.append(token.text)\n",
    "        else:\n",
    "            for token in doc:\n",
    "                if token.dep_ == \"nsubj\" or token.dep_ == \"conj\":\n",
    "                    if token.ent_type_ == \"PARTY\" or token.ent_type_ == \"PARTY_TITLE\" \\\n",
    "                    or token.ent_type_ in [\"PARTY\", \"PARTY_TITLE\", \"ORG\", \"PROPN\", \"PERSON\", \"GPE\"]:\n",
    "                        temp_nsubj.append(token.text)\n",
    "        if len(temp_nsubj) == 0: \n",
    "            for token in doc:\n",
    "                pass\n",
    "        elif len(temp_nsubj) == 1:\n",
    "            loader.append(temp_nsubj[0])\n",
    "            return loader\n",
    "        else:\n",
    "            sents = doc.text.split(\",\")\n",
    "            for i in sents:\n",
    "                if re.search(money_re, i) is not None:\n",
    "                    temp_doc = nlp(i)\n",
    "                    for temp_token in temp_doc:\n",
    "                        if temp_token.dep_ == \"nsubj\" and temp_token.ent_type_ in [\"PARTY\", \\\n",
    "                                                                                   \"PARTY_TITLE\", \\\n",
    "                                                                                   \"ORG\", \"PROPN\", \\\n",
    "                                                                                   \"PERSON\", \"GPE\"]:\n",
    "                            loader.append(temp_token.text)\n",
    "                            break\n",
    "            if len(loader) == 0:\n",
    "                loader = [temp_nsubj[0]]\n",
    "                    \n",
    "    if invalid_cost: loader = [invalid_cost]   \n",
    "    return loader\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# 处理 judgement result的方法\n",
    "def extract_judgement_result(t):\n",
    "#     print(\"nlp pipelines in extract judgement result method:\", nlp.pipe_names)\n",
    "    t = t.replace(\"\\n\", \"\")\n",
    "    t = t[:-1] #去掉最后一个符号\n",
    "    t = re.sub(r'[一二三四五六七八九十]、', '', t)\n",
    "    if re.search(money_re, t) is None: return []\n",
    "    else:\n",
    "        if \"。\" in t: sents = t.split(\"。\")\n",
    "        elif \";\" in t: sents = t.split(\";\")\n",
    "        else: sents = [t]\n",
    "        final_result = []\n",
    "        for i in sents:\n",
    "            #这里先好好处理单个句子，不考虑是针对某个案件的，先把不同种类的句子都处理好\n",
    "            #先提取(cost_type, money_amount)\n",
    "            temp_extracted_infos = [] #example: [('受理费', '25元', '重庆永辉超市有限公司')]\n",
    "            judgere_doc = nlp(i)\n",
    "            if re.search(money_re, judgere_doc.text) is not None:\n",
    "#                 输出案件结果的实体识别和文本附加信息\n",
    "#                 displacy.render(judgere_doc, style=\"ent\")\n",
    "#                 for token in judgere_doc:\n",
    "#                     print(token.text, token.pos_, token.dep_, token.ent_type_, token.head.text, token.head.pos_,\n",
    "#                             [child for child in token.children])\n",
    "#                 print()\n",
    "                has_cost_type = False\n",
    "                for d in judgere_doc.ents:\n",
    "                    if d.label_ == \"COST_TYPE\":\n",
    "                        has_cost_type = True\n",
    "                        #temp_cost_type.append(d.text)\n",
    "                        temp_extracted_info = [d.text, '', '']\n",
    "                    if d.label_ == \"MONEY_AMOUNT\":\n",
    "                        if has_cost_type:\n",
    "                            temp_extracted_info[1] = d.text\n",
    "                            has_cost_type = False\n",
    "                        else:\n",
    "                            temp_extracted_info = [\"统一赔偿费用\", d.text, '']\n",
    "                        temp_extracted_infos.append(temp_extracted_info)\n",
    "                \n",
    "                loader = extract_loader(judgere_doc)\n",
    "                if len(loader) > 0 and loader[0] == True: \n",
    "                    temp_extracted_infos = []\n",
    "                else:\n",
    "                    for tr in temp_extracted_infos:\n",
    "                        tr[2] = loader\n",
    "                    final_result += temp_extracted_infos\n",
    "    return final_result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "hide_input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#获取当事人信息,将当事人的称号保存至字典中\n",
    "# re part\n",
    "# party_re = r'(?P<party_title>[\\u4e00-\\u9fa5()]*):'\n",
    "party_re = r'(?P<party_title>[\\u4e00-\\u9fa5]*:|[[\\u4e00-\\u9fa5]*\\([^()]*\\)]*:)'\n",
    "case_truth_list = ['事实', '购买', '标签']\n",
    "case_truth_re_1 = r'([，。;:][^，。;:]*事实[^，。;]*[，。;])'\n",
    "case_truth_re_2 = r'([，。;:][^，。;:]*购买[^，。;]*[，。;])'\n",
    "case_truth_re_3 = r'([，。;:][^，。;:]*标签[^，。;]*[，。;])'\n",
    "case_truth_re_4 = r'([，。;:][^，。;:]*不符合[^，。;]*[，。;])'\n",
    "case_truth_re_4 = r'([，。;:][^，。;:]*不符合[^，。;]*[，。;])'\n",
    "case_truth_re_5 = r'([，。;:][^，。;:]*生产日期[^，。;]*[，。;]|[，。;:][^，。;:]*保质期[^，。;]*[，。;])'\n",
    "court_opin_re_1 = r'([，。;:][^，。;:]*焦点[^，。;]*[，。;])'\n",
    "court_opin_re_2 = r'([，。;:][^，。;:]*消费者[^，。;]*[，。;])'\n",
    "court_opin_re_3 = r'([，。;:][^，。;:]*支持[^，。;]*[，。;])'\n",
    "# judgement_result_re = r'([^，。;:][^，。;:]*元[^，。;]*[，。;])' #只match带有金额的句子\n",
    "# case_truth_relist = {'case_truth_re_1':0, 'case_truth_re_2':0, 'case_truth_re_3':0, 'case_truth_re_4':0, 'case_truth_re_5':0}\n",
    "# court_opin_relist = {'court_opin_re_1':0, 'court_opin_re_2':0, 'court_opin_re_3':0}\n",
    "\n",
    "# judgere_type_re = r\"(?P<cost_type>(货款|价款|受理费|赔偿金|公证费|诉讼费|购物款|上诉费|公告费|交通费|误工费|打印费|鉴定费|邮寄费|赔偿款|医疗费|购酒款|购药款|住宿费|产品质量监督检验费|其他费用))([损失|共计|减半收取|用|为]*)?(?P<amount>([零一二三四五六七八九十百千万亿角元]*|(人民币)?(\\d+((\\.|,)\\d+)?))[角|元])\"\n",
    "# judgere_relation_re_1 = r\"(向(?P<benefit_person_3>(原告|被告|上诉人|被上诉人))[\\u4e00-\\u9fa5]*)?(退还|赔偿|返还|支付)(?P<benefit_person_1>(原告|被告|上诉人|被上诉人))?[^零一二三四五六七八九十百千万亿角元\\d.,]*(?P<amount>([零一二三四五六七八九十百千万亿角元]*|(人民币)?(\\d+((\\.|,)\\d+)?))[角|元])(给)?(?P<benefit_person_2>(原告|被告|上诉人|被上诉人))?\" #这部分amonut与nltk ipynb中的不一样\n",
    "# judgere_relation_re_2 = r'(?P<punished_person>(原告|被告|上诉人|被上诉人))[\\u4e00-\\u9fa5“”、(),]*(共同)?(承|负)担'\n",
    "\n",
    "def process_one_case(dict_data, case_id, entityruler):\n",
    "    # re-result set part\n",
    "    party_titles = set() #当事人称号的字典\n",
    "    party_info_titles = set() #当事人个人信息类别字典\n",
    "    party_dicts = {} #案例id：案例当事人信息\n",
    "    party_dict_list = []\n",
    "    judge_list = []\n",
    "    case_truth_str = \"\" #从json中提取的案件事实的总体文本内容\n",
    "    court_opin_str = \"\" #从json中提取的法院意见的总体文本内容，同上，均用于正则匹配\n",
    "    case_truth_result = [] #案件事实正则匹配结果集\n",
    "    court_opin_result = [] #法院意见正则匹配结果集\n",
    "    # judgement_result_str = \"\"\n",
    "    total_judgement_result_list = []\n",
    "    case_truth_relist = {'case_truth_re_1':0, 'case_truth_re_2':0, 'case_truth_re_3':0, 'case_truth_re_4':0, 'case_truth_re_5':0}\n",
    "    court_opin_relist = {'court_opin_re_1':0, 'court_opin_re_2':0, 'court_opin_re_3':0}\n",
    "    keyword_text_list = [\"\"]*16 #长度16，对应8个keyword的re以及没匹配到的情况\n",
    "    # judgere_dict = {}\n",
    "    party_str = [] #当事人信息的文本list\n",
    "    judgeresult_str = [] #案件处理结果的文本list（用作nltk进一步处理）\n",
    "    result_keyword = \"unknown\"#二审和再审的关键字（维持or撤销），用来判断赢率\n",
    "\n",
    "    # processing part\n",
    "    # first_judge = False\n",
    "    case_id = case_id\n",
    "\n",
    "    #法院名称\n",
    "    court_name = dict_data['returnData']['court']\n",
    "    # print(court_name)\n",
    "\n",
    "    #审判日期\n",
    "    judgement_date = dict_data['returnData']['judgementDate']\n",
    "    # print(judgement_date)\n",
    "\n",
    "    #审级\n",
    "    procedure = dict_data['returnData']['procedure']\n",
    "    # print(procedure)\n",
    "\n",
    "    #案由\n",
    "    reason = dict_data['returnData']['reason']\n",
    "    # print(reason)\n",
    "\n",
    "    for i in dict_data['returnData']['segments']:\n",
    "        judgement_result_list = []\n",
    "        person_m2, person_m3 = \"\", \"\"\n",
    "        #处理当事人信息\n",
    "        if i['typeText'] == '当事人':\n",
    "#             print(i['text'])\n",
    "            party_dict = {} #当事人title：当事人信息\n",
    "            party_str.append(i['text'])\n",
    "            s = i['text'][:-1] #去掉句号\n",
    "            # print(s)\n",
    "            ii = s.split(\",\")\n",
    "            for iii in ii:\n",
    "#                 print(iii)\n",
    "                doc = nlp(iii)\n",
    "\n",
    "                #出生日期\n",
    "                # print(\"processing birth date\\n\")\n",
    "                # party_dict['birth_date'] = \"未知\"\n",
    "                re_date = r\"\\d{2,4}年\\d{1,2}月\\d{1,2}日\"\n",
    "                date_m = re.findall(re_date, iii)\n",
    "                if len(date_m) > 0:\n",
    "                    party_dict['birth_date'] = date_m[0]\n",
    "                    \n",
    "                #性别\n",
    "                # print(\"processing gender\\n\")\n",
    "                # party_dict['gender'] = \"未知\"\n",
    "                re_gender = r\"男|女\"\n",
    "                gender_m = re.findall(re_gender, iii)\n",
    "                if len(gender_m)>0:\n",
    "                    party_dict['gender'] = gender_m[0]\n",
    "\n",
    "                #title+姓名\n",
    "#                 print(\"processing party title\\n\")\n",
    "                \n",
    "                # Use Token matcher to replace Phrase matcher\n",
    "#                 matcher_title = PhraseMatcher(nlp2.vocab)\n",
    "                matcher_title = Matcher(nlp.vocab)\n",
    "    \n",
    "#                 matcher_title.add(\"PARTY_TITLES\", None, *patterns_ptitles2)\n",
    "                matcher_title.add(\"PARTY_TITLES\", [partytitle_token_pattern])\n",
    "    \n",
    "                matches_title = matcher_title(doc)\n",
    "#                 print(\"matches_title: \", matches_title)\n",
    "                if len(matches_title) > 0:\n",
    "                    temp_matches = [end-start for match_id, start, end in matches_title]\n",
    "                    #如果有多个匹配结果，就取长度最长的匹配作为最终结果\n",
    "                    final_index = temp_matches.index(max(temp_matches))\n",
    "                    temp_party_result = [(doc[start:end], (start, end)) for match_id, start, end in matches_title][final_index]\n",
    "                    temp_key = str(temp_party_result[0])\n",
    "                    party_name = str(doc[temp_party_result[1][1]:]).replace(\":\", \"\")\n",
    "                    # party_dict[temp_key] = party_name\n",
    "                    party_dict['title'] = temp_key\n",
    "                    party_dict['name'] = party_name\n",
    "\n",
    "                #职业\n",
    "                # party_dict['occupation'] = \"未知\"\n",
    "                # print(\"processing occupation\\n\")\n",
    "                matcher_occup = PhraseMatcher(nlp.vocab)\n",
    "                # patterns_poccups = list(nlp.pipe(party_occupations))\n",
    "                matcher_occup.add(\"PARTY_OCCUPS\", None, *patterns_poccups)\n",
    "                matches_occup = matcher_occup(doc)\n",
    "                if len(matches_occup) > 0:\n",
    "                    temp_matches = [end-start for match_id, start, end in matches_occup]\n",
    "                    final_index = temp_matches.index(max(temp_matches))\n",
    "                    temp_party_result =  [(doc[start:end], (start, end)) for match_id, start, end in matches_occup][final_index]\n",
    "                    party_dict['occupation'] = str(temp_party_result[0])\n",
    "                \n",
    "                #其他补充信息\n",
    "                # print(\"processing party info\\n\")\n",
    "                matcher_info = PhraseMatcher(nlp.vocab)\n",
    "                # patterns_pinfos = list(nlp.pipe(party_infos))\n",
    "                matcher_info.add(\"PARTY_INFOS\", None, *patterns_pinfos)\n",
    "                matches_info = matcher_info(doc)\n",
    "                if len(matches_info) > 0:\n",
    "                    temp_matches = [end-start for match_id, start, end in matches_info]\n",
    "                    final_index = temp_matches.index(max(temp_matches))\n",
    "                    temp_party_result =  [(doc[start:end], (start, end)) for match_id, start, end in matches_info][final_index]\n",
    "                    temp_key = str(temp_party_result[0])\n",
    "                    temp_info = str(doc[temp_party_result[1][1]:])\n",
    "                    party_dict[temp_key] = temp_info\n",
    "            party_dict_list.append(party_dict)\n",
    "            if 'name' in party_dict.keys():\n",
    "#                 print(\"要被加到entityruler里的当事人有：\", str(party_dict['name']))\n",
    "                entityruler.add_patterns([{\"label\": \"PARTY\", \"pattern\": party_dict['name']}])\n",
    "                nlp.tokenizer.pkuseg_update_user_dict([party_dict['name']])\n",
    "        \n",
    "        #审判人员\n",
    "        if i['type'] == \"JUDGE\" and \"审\" in i['text']:\n",
    "            judge_list.append(i['text']) #TODO\n",
    "            # print(judge)\n",
    "        \n",
    "        # 审判结果\n",
    "        if i['type'] == \"JUDGEMENT_RESULT\":\n",
    "            if \"维持\" in i['text']: result_keyword = \"维持\"\n",
    "            if \"撤销\" in i['text']: result_keyword = \"撤销\"\n",
    "            judgeresult_str.append(i['text'])\n",
    "            temp_results = extract_judgement_result(i['text'])\n",
    "            if len(temp_results) > 0:\n",
    "                total_judgement_result_list.append(temp_results)\n",
    "        \n",
    "        #案件事实\n",
    "        if i['type'] == \"PLAINTIFF_WORDS\" or i['type'] == \"DEFENDANT_WORDS\" or \\\n",
    "            i['type'] == \"ASCERTAIN\" or i['type'] == \"EVIDENCE\" or i['type'] == \"COUNTER_WORDS\":\n",
    "            case_truth_str += i['text']\n",
    "\n",
    "        #法院意见\n",
    "        if i['type'] == \"COURT_HELD\" or i['type'] == \"courtHeld\":\n",
    "            court_opin_str += i['text']\n",
    "\n",
    "    # print(case_truth_str)\n",
    "    # print(court_opin_str)\n",
    "    # print(judgement_result_str)\n",
    "\n",
    "    # 处理案件事实文本(计算每种re是否成功在文本中有内容匹配，法院意见同理)\n",
    "    cc = 0\n",
    "    for k, v in case_truth_relist.items():\n",
    "        temp = re.findall(eval(k), case_truth_str)\n",
    "        if len(temp) > 0:\n",
    "            case_truth_relist[k] += 1\n",
    "            case_truth_result += temp\n",
    "            keyword_text_list[cc] = case_truth_str\n",
    "        else:\n",
    "            keyword_text_list[cc+1] = case_truth_str\n",
    "        cc += 2\n",
    "\n",
    "\n",
    "    # 处理法院意见文本\n",
    "    cc = 10\n",
    "    for k, v in court_opin_relist.items():\n",
    "        temp = re.findall(eval(k), court_opin_str)\n",
    "        if len(temp) > 0:\n",
    "            court_opin_relist[k] += 1\n",
    "            court_opin_result += temp\n",
    "            keyword_text_list[cc] = court_opin_str\n",
    "        else:\n",
    "            keyword_text_list[cc+1] = court_opin_str\n",
    "        cc += 2\n",
    "    \n",
    "    # 提取审判人员信息（取第一个人的名字即可）\n",
    "    party_dicts['judge'] = \"\"\n",
    "    if len(judge_list) > 0:\n",
    "        judge_text = judge_list[0].replace(\" \", \"\")\n",
    "        matcher_jt = PhraseMatcher(nlp.vocab)\n",
    "        patterns_jtitles = [nlp.make_doc(text) for text in judge_titles]\n",
    "        matcher_jt.add(\"JUDGE_TITLE\", patterns_jtitles)\n",
    "        doc_jt = nlp(judge_text)\n",
    "        matches_jt = matcher_jt(doc_jt)\n",
    "        if len(matches_jt) > 0:\n",
    "            match_list = [(start, end) for match_id, start, end in matches_jt]\n",
    "            start = match_list[0][1]\n",
    "            end = len(doc_jt)\n",
    "            for i in range(1, len(match_list)):\n",
    "                temp_end = match_list[i][0]\n",
    "                if temp_end > start: \n",
    "                    end = temp_end\n",
    "                    break\n",
    "            final_judge = doc_jt[start:end].text\n",
    "            party_dicts['judge'] = final_judge\n",
    "        else: party_dicts['judge'] = judge_text\n",
    "\n",
    "        \n",
    "    party_dicts[\"case_id\"] = case_id\n",
    "    party_dicts[\"party_info\"] = party_dict_list\n",
    "    party_dicts[\"judgement_date\"] = judgement_date\n",
    "    party_dicts[\"procedure\"] = procedure\n",
    "    party_dicts[\"reason\"] = reason\n",
    "    party_dicts[\"court_name\"] = court_name\n",
    "    party_dicts['case_truth'] = set(case_truth_result)\n",
    "    party_dicts['court_opinion'] = set(court_opin_result)\n",
    "    party_dicts['judgement_result'] = total_judgement_result_list\n",
    "    party_dicts['judgere_keyword'] = result_keyword\n",
    "\n",
    "    \n",
    "    return party_titles, party_info_titles, case_truth_relist, court_opin_relist, \\\n",
    "            party_dicts, party_str, judgeresult_str, entityruler\\\n",
    "#             keyword_text_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer', 'money_amount', 'tagger', 'parser', 'ner', 'global_entityruler', 'attribute_ruler', 'merge_entities']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代理审判员, 何思静\n",
      "0 1\n",
      "代理审判员\n",
      "match_list:  [(0, 1)]\n",
      "start:  1\n",
      "end:  2\n",
      "何思静\n"
     ]
    }
   ],
   "source": [
    "# judge text test\n",
    "judge_text = \"代理审判员何思静\"\n",
    "patterns_jtitles = [nlp.make_doc(text) for text in judge_titles]\n",
    "doc_test = nlp(judge_text)\n",
    "matcher_jt = PhraseMatcher(nlp.vocab)\n",
    "matcher_jt.add(\"JUDGE_TITLE\", patterns_jtitles)\n",
    "matches_jt = matcher_jt(doc_test)\n",
    "print(str(\", \").join([str(i) for i in doc_test]))\n",
    "\n",
    "for match_id, start, end in matches_jt:\n",
    "    print(start, end)\n",
    "    span = doc_test[start:end]\n",
    "    print(span.text)\n",
    "\n",
    "match_list = [(start, end) for match_id, start, end in matches_jt]\n",
    "print(\"match_list: \", match_list)\n",
    "start = match_list[0][1]\n",
    "print(\"start: \", start)\n",
    "end = len(doc_test)\n",
    "for i in range(1, len(match_list)):\n",
    "    temp_end = match_list[i][0]\n",
    "    if temp_end > start: \n",
    "        end = temp_end\n",
    "        break\n",
    "print(\"end: \", end)\n",
    "print(doc_test[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "委托代理人 PARTY_TITLE\n",
      "原告 PARTY_TITLE\n"
     ]
    }
   ],
   "source": [
    "matcher_title = Matcher(nlp.vocab)\n",
    "matcher_title.add(\"PARTY_TITLE\", [partytitle_token_pattern])\n",
    "on_match, patterns = matcher_title.get(\"PARTY_TITLE\")\n",
    "# print(patterns)\n",
    "doc_test = nlp(\"委托代理人张文利,女,汉族,1987年11月2日出生,住址陕西省蒲城县,系原告配偶。99.9元,与原告系夫妻关系,原告刘猛\")\n",
    "matches_title = matcher_title(doc_test, as_spans=True)\n",
    "# print(doc_test[0])\n",
    "for span in matches_title:\n",
    "    print(span.text, span.label_)\n",
    "# for match_id, start, end in matches_title:\n",
    "#     string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "#     span = doc_test[start:end]  # The matched span\n",
    "#     print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process one case test\n",
    "party_entityruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "i = \"type2\"\n",
    "j = \"2017\"\n",
    "k = \"11\"\n",
    "party_entityruler_pattern_path = total_basic_url + \"party_entityruler_files/\" + \"entityruler_patterns_\" + str(i) + \"_\" + str(j) + \"_\" + str(k) + \".jsonl\"\n",
    "party_entityruler.from_disk(party_entityruler_pattern_path)\n",
    "name = \"party_entityruler_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)\n",
    "# if name not in list(nlp.pipe_names):\n",
    "#     nlp.add_pipe(party_entityruler, name=name, before=\"ner\")\n",
    "# if name not in list(nlp2.pipe_names):\n",
    "#     nlp2.add_pipe(party_entityruler, name=name, before=\"ner\")\n",
    "party_titles, party_info_titles, case_truth_relist, \\\n",
    "court_opin_relist, party_dicts, party_str, judgeresult_str, entityruler = process_one_case(dict_data, \"test\", party_entityruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'judge': '江红虹',\n",
       " 'case_id': 'test',\n",
       " 'party_info': [{'title': '原告',\n",
       "   'name': '许鹏飞',\n",
       "   'gender': '男',\n",
       "   'birth_date': '1982年8月8日'},\n",
       "  {'title': '委托代理人',\n",
       "   'name': '张文利',\n",
       "   'gender': '女',\n",
       "   'birth_date': '1987年11月2日',\n",
       "   '住址': '陕西省蒲城县'},\n",
       "  {'title': '被告', 'name': '尹真贤', 'birth_date': '1987年9月27日'}],\n",
       " 'judgement_date': '2017-11-20',\n",
       " 'procedure': '一审',\n",
       " 'reason': '产品责任纠纷',\n",
       " 'court_name': '广东省深圳市福田区人民法院',\n",
       " 'case_truth': {';生产日期:201610;',\n",
       "  '。以上事实,有原告提交的相应产品实物照片、交易快照、商品信息等证据及开庭笔录为证,本院予以确认。',\n",
       "  '。原告收到后发现其为假药或不符合标准的产品。',\n",
       "  '。另查,涉案产品说明书为网络截图,原告收到的涉案产品无附带说明书,也无生产日期、生产企业、合格证等任何标识,仅包装盒和药品瓶身印有“ELEPHANT”字样。',\n",
       "  '。经审理查明,原告于2017年5月23日通过淘宝网账户“张明zwlxpf”在被告淘宝网店“性用品批发商520”处购买了5瓶“2017印度巨象代购正品持久神油口男服用保健品勃起提高性功能”(即涉案产品),订单编号为22233728684034085,单价398元,经优惠省998.98元,涉案产品总价991.02元。'},\n",
       " 'court_opinion': {'。原告要求被告退还货款991.02元,本院予以支持;'},\n",
       " 'judgement_result': [[['货款', '991.02元', ['尹真贤']],\n",
       "   ['统一赔偿费用', '9910.2元', ['尹真贤']]],\n",
       "  [['受理费', '75元', ['被告']]]],\n",
       " 'judgere_keyword': 'unknown'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing multiple json files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对多个json文件试一下\n",
    "def process_batch_cases(dir_path, entityruler):\n",
    "    if not os.path.exists(dir_path):\n",
    "        print(\"路径不存在！\", dir_path)\n",
    "        return\n",
    "    case_count = 0\n",
    "    party_titles = set() #当事人称号的字典\n",
    "    party_info_titles = set() #当事人个人信息类别字典\n",
    "    case_dict_lists = [] #一个文件夹下的案例处理后要存入的集合\n",
    "    party_strs = [] #当事人信息的文本list\n",
    "    judgeresult_strs = []\n",
    "    case_truth_re = {}\n",
    "    court_opin_re = {}\n",
    "    case_truth_re_1_ = r'([，。;:][^，。;:]*事实[^，。;]*[，。;])'\n",
    "    case_truth_re_2 = r'([，。;:][^，。;:]*购买[^，。;]*[，。;])'\n",
    "    case_truth_re_3 = r'([，。;:][^，。;:]*标签[^，。;]*[，。;])'\n",
    "    case_truth_re_4 = r'([，。;:][^，。;:]*不符合[^，。;]*[，。;])'\n",
    "    case_truth_re_5 = r'([，。;:][^，。;:]*生产日期[^，。;]*[，。;]|[，。;:][^，。;:]*保质期[^，。;]*[，。;])'\n",
    "    court_opin_re_1 = r'([，。;:][^，。;:]*焦点[^，。;]*[，。;])'\n",
    "    court_opin_re_2 = r'([，。;:][^，。;:]*消费者[^，。;]*[，。;])'\n",
    "    court_opin_re_3 = r'([，。;:][^，。;:]*支持[^，。;]*[，。;])'\n",
    "#     judgement_result_re = r'([^，。;:][^，。;:]*元[^，。;]*[，。;])' #只match带有金额的句子\n",
    "    keyword_text_lists = []\n",
    "    print(\"----------------------------executing path: \", dir_path)\n",
    "\n",
    "    # path = \"/Users/starice/OwnFiles/cityu/RA/type1/2014/3/json\" #文件夹目录\n",
    "    files = os.listdir(dir_path) #得到文件夹下的所有文件名称\n",
    "    for file in files: #遍历文件夹\n",
    "        if os.path.splitext(file)[-1][1:] != \"json\": continue\n",
    "        case_count += 1\n",
    "        case_id = file.split(\".\")[0]\n",
    "        if not os.path.isdir(file): #判断是否是文件夹，不是文件夹才打开\n",
    "            with open(dir_path + \"/\" + file, 'r', encoding=\"UTF-8\") as f: data = json.load(f)\n",
    "            dict_data = json.loads(data)\n",
    "            _party_titles, _party_info_titles, _case_truth_relist, _court_opin_relist, \\\n",
    "            _party_dicts, _party_str, _judgeresult_str, _entityruler = \\\n",
    "            process_one_case(dict_data, case_id, entityruler)\n",
    "                # _keyword_text_list\n",
    "            party_titles.union(_party_titles)\n",
    "            party_info_titles.union(_party_info_titles)\n",
    "            case_dict_lists.append(_party_dicts)\n",
    "            case_truth_re = merge_dict(case_truth_re, _case_truth_relist)\n",
    "            court_opin_re = merge_dict(court_opin_re, _court_opin_relist)\n",
    "            party_strs += _party_str\n",
    "            judgeresult_strs += _judgeresult_str\n",
    "            # print(party_strs)\n",
    "            # keyword_text_lists.append(_keyword_text_list)\n",
    "    return party_titles, party_info_titles, case_truth_re, court_opin_re, case_dict_lists, \\\n",
    "            case_count, party_strs, judgeresult_strs, _entityruler\\\n",
    "#             , keyword_text_lists\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = \"/Users/starice/OwnFiles/cityu/RA/\"\n",
    "pre_dir = ['type1', 'type2', 'type3', 'type4']\n",
    "dir_name = ['2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "dir_sname = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n",
    "party_titles = set()\n",
    "party_info_titles = set()\n",
    "total_judgement_result = []\n",
    "\n",
    "def switch_dict_0(pre_dir, dir_name, dir_sname, entityruler):\n",
    "    entityruler.to_disk(total_basic_url + \"party_entityruler_files/\" + \"entityruler_patterns_\" + str(pre_dir) + \"_\" + str(dir_name) + \"_\" + str(dir_sname) + \".jsonl\")\n",
    "\n",
    "def switch_dict_1(pre_dir, dir_name, dir_sname, _case_dict_lists):\n",
    "    with open(total_basic_url + \"total_dict_result/\" + \"dict_result_\" + str(pre_dir) + \"_\" + str(dir_name) + \"_\" + str(dir_sname) + \".txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "        for case_dict in _case_dict_lists:\n",
    "            f.write(str(case_dict) + \"\\n\")\n",
    "    name = \"party_entityruler_\"+str(pre_dir)+\"_\"+str(dir_name)+\"_\"+str(dir_sname)\n",
    "    nlp.remove_pipe(name)\n",
    "    \n",
    "\n",
    "def switch_default():\n",
    "    print(\"This method is just for switch dict structure.\")\n",
    "\n",
    "#     The control_number refers to many file actions(will be defined later TODO)\n",
    "def process_multiple_cases(pre_dir, dir_name, dir_sname, control_number):\n",
    "    total_count = 0\n",
    "    total_case_truth_re = {}\n",
    "    total_court_opin_re = {}\n",
    "    for i in pre_dir:\n",
    "        for j in dir_name:\n",
    "            for k in dir_sname:\n",
    "                \n",
    "                url = base_url + i + \"/\" + j + \"/\" + k + \"/json\"\n",
    "                config={\"overwrite_ents\": True}\n",
    "                entityruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "                \n",
    "#                 处理哪部分case文件就引入哪部分的party patterns\n",
    "                party_entityruler_pattern_path = total_basic_url + \"party_entityruler_files/\" + \"entityruler_patterns_\" + str(i) + \"_\" + str(j) + \"_\" + str(k) + \".jsonl\"\n",
    "                if not os.path.exists(party_entityruler_pattern_path):\n",
    "                    print(\"Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！\", party_entityruler_pattern_path)\n",
    "                else:\n",
    "#                     party_entityruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "#                     party_entityruler.from_disk(party_entityruler_pattern_path)\n",
    "                    name = \"party_entityruler_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)\n",
    "                    if name not in list(nlp.pipe_names):\n",
    "                        party_entityruler = nlp.add_pipe(\"entity_ruler\", name=name, after=\"ner\", config=config)\n",
    "                        party_entityruler.from_disk(party_entityruler_pattern_path)\n",
    "#                         nlp.add_pipe(party_entityruler, name=name, after=\"ner\")\n",
    "                \n",
    "                process_batchcases_result = process_batch_cases(url, entityruler)\n",
    "                if process_batchcases_result is not None:\n",
    "                    _party_titles, _party_info_titles, _case_truth_re, _court_opin_re, \\\n",
    "                    _case_dict_lists, _case_count, _party_strs, _judgeresult_strs, \\\n",
    "                    _entityruler = process_batchcases_result[0], process_batchcases_result[1], \\\n",
    "                    process_batchcases_result[2], process_batchcases_result[3], process_batchcases_result[4], \\\n",
    "                    process_batchcases_result[5], process_batchcases_result[6], process_batchcases_result[7], \\\n",
    "                    process_batchcases_result[8]\n",
    "                    #_case_count, _keyword_text_lists\n",
    "                    \n",
    "                    party_titles.union(_party_titles)\n",
    "                    party_info_titles.union(_party_info_titles)\n",
    "                    total_count += _case_count\n",
    "                    total_case_truth_re = merge_dict(total_case_truth_re, _case_truth_re)\n",
    "                    total_court_opin_re = merge_dict(total_court_opin_re, _court_opin_re)\n",
    "                    \n",
    "                    #control number stage\n",
    "                    if control_number == 0:\n",
    "                        switch_dict_0(i, j, k, _entityruler)\n",
    "                    elif control_number == 1: \n",
    "                        switch_dict_1(i, j, k, _case_dict_lists)\n",
    "                    else: switch_default()\n",
    "                        \n",
    "                else: print(\"Unsuccessfully processed directory: \", url, \" !\")\n",
    "                    \n",
    "    #输出案件事实和法院意见关键字的匹配程度\n",
    "    print(\"共处理了 \", total_count, \" 个案件，案件事实和法院意见关键字的匹配程度如下：\")\n",
    "    print(total_case_truth_re)\n",
    "    print(total_court_opin_re)\n",
    "\n",
    "#                 #写总的处理结果到文件\n",
    "#                 with open(\"/Users/starice/Desktop/total_dict_result/\"+\"dict_result_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)+\".txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                     for case_dict in _case_dict_lists:\n",
    "#                         f.write(str(case_dict) + \"\\n\")\n",
    "\n",
    "#     #             写模型处理后的当事人信息到文件\n",
    "#                 with open(\"/Users/starice/Desktop/partyinfo_result_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)+\"_text.txt\"\\\n",
    "#                 , 'w', encoding=\"UTF-8\") as f:\n",
    "#                     for case_dict in _case_dict_lists:\n",
    "#                         f.write(str(case_dict['case_id']) + \"\\n\")\n",
    "#                         for info in case_dict['party_info']:\n",
    "#                             f.write(str(info) + \"\\n\")\n",
    "#                         f.write(\"\\n\\n\")\n",
    "\n",
    "#                 # 写当事人信息文本到文件\n",
    "#                 with open(\"/Users/starice/Desktop/partyinfo_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)+\"_text.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                     for p in _party_strs:\n",
    "#                         f.write(str(p) + \"\\n\")\n",
    "\n",
    "#                 # 写案件处理结果文本（json中的原有文本）到文件\n",
    "#                 with open(\"/Users/starice/Desktop/judgeresult_\"+str(i)+\"_\"+str(j)+\"_\"+str(k)+\"_text.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                     for j in _judgeresult_strs:\n",
    "#                         f.write(str(j) + \"\\n\")\n",
    "\n",
    "#                 写案件处理结果文本到文件\n",
    "#                 for c in _case_dict_lists:\n",
    "#                     total_judgement_result.append(c['judgement_result'])\n",
    "#                 with open(\"/Users/starice/Desktop/judgement_result.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                     for r in total_judgement_result:\n",
    "#                         f.write(str(r) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/1/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/2/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/3/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/4/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/5/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/6/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/7/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/8/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/9/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/10/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/11/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2019/12/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2020/1/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2020/2/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2020/3/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2020/4/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2020/5/json\n",
      "----------------------------executing path:  /Users/starice/OwnFiles/cityu/RA/type4/2020/6/json\n",
      "Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！ /Users/starice/Desktop/party_entityruler_files/entityruler_patterns_type4_2020_7.jsonl\n",
      "路径不存在！ /Users/starice/OwnFiles/cityu/RA/type4/2020/7/json\n",
      "Unsuccessfully processed directory:  /Users/starice/OwnFiles/cityu/RA/type4/2020/7/json  !\n",
      "Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！ /Users/starice/Desktop/party_entityruler_files/entityruler_patterns_type4_2020_8.jsonl\n",
      "路径不存在！ /Users/starice/OwnFiles/cityu/RA/type4/2020/8/json\n",
      "Unsuccessfully processed directory:  /Users/starice/OwnFiles/cityu/RA/type4/2020/8/json  !\n",
      "Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！ /Users/starice/Desktop/party_entityruler_files/entityruler_patterns_type4_2020_9.jsonl\n",
      "路径不存在！ /Users/starice/OwnFiles/cityu/RA/type4/2020/9/json\n",
      "Unsuccessfully processed directory:  /Users/starice/OwnFiles/cityu/RA/type4/2020/9/json  !\n",
      "Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！ /Users/starice/Desktop/party_entityruler_files/entityruler_patterns_type4_2020_10.jsonl\n",
      "路径不存在！ /Users/starice/OwnFiles/cityu/RA/type4/2020/10/json\n",
      "Unsuccessfully processed directory:  /Users/starice/OwnFiles/cityu/RA/type4/2020/10/json  !\n",
      "Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！ /Users/starice/Desktop/party_entityruler_files/entityruler_patterns_type4_2020_11.jsonl\n",
      "路径不存在！ /Users/starice/OwnFiles/cityu/RA/type4/2020/11/json\n",
      "Unsuccessfully processed directory:  /Users/starice/OwnFiles/cityu/RA/type4/2020/11/json  !\n",
      "Entityruler patterns file 路径不存在！使用默认的entity ruler可能会影响金额承担者的提取！ /Users/starice/Desktop/party_entityruler_files/entityruler_patterns_type4_2020_12.jsonl\n",
      "路径不存在！ /Users/starice/OwnFiles/cityu/RA/type4/2020/12/json\n",
      "Unsuccessfully processed directory:  /Users/starice/OwnFiles/cityu/RA/type4/2020/12/json  !\n",
      "共处理了  644  个案件，案件事实和法院意见关键字的匹配程度如下：\n",
      "{'case_truth_re_1': 583, 'case_truth_re_2': 547, 'case_truth_re_3': 390, 'case_truth_re_4': 418, 'case_truth_re_5': 353}\n",
      "{'court_opin_re_1': 91, 'court_opin_re_2': 552, 'court_opin_re_3': 609}\n"
     ]
    }
   ],
   "source": [
    "# self-defined whole process\n",
    "\n",
    "# 1. Output the entityruler patterns file(one times for one directory)\n",
    "# process_multiple_cases(pre_dir[1:2], dir_name[3:4], dir_sname[10:11], 0)\n",
    "# print(nlp.pipe_names)\n",
    "\n",
    "# 2. Output all extracted results which are classified by their categories\n",
    "# process_multiple_cases(pre_dir[3:4], dir_name[5:], dir_sname[:], 1)\n",
    "# print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #只有在上面的代码有返回_keyword_text_lists时才运行，用于输出案件事实和法院意见\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_1_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[0] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_1_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[1] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_2_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[2] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_2_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[3] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_3_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[4] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_3_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[5] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_4_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[6] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_4_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[7] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_5_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[8] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"case_truth_re_5_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[9] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"court_opin_re_1_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[10] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"court_opin_re_1_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[11] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"court_opin_re_2_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[12] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"court_opin_re_2_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[13] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"court_opin_re_3_matched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[14] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")\n",
    "# with open(\"/Users/starice/Desktop/\"+\"court_opin_re_3_unmatched.txt\", 'w', encoding=\"UTF-8\") as f:\n",
    "#                 for temp in [i[15] for i in _keyword_text_lists]:\n",
    "#                     f.write(str(temp) + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
